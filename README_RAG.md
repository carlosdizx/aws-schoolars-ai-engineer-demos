# Sistema RAG con Amazon Bedrock

Este proyecto implementa un sistema de **GeneraciÃ³n Aumentada por RecuperaciÃ³n (RAG)** usando Amazon Bedrock, ChromaDB y modelos de IA de Ãºltima generaciÃ³n.

## ğŸ¯ Objetivos del Ejercicio

- Implementar un sistema RAG bÃ¡sico usando Amazon Bedrock
- Seleccionar modelos adecuados para embeddings y generaciÃ³n de texto
- Desarrollar indexaciÃ³n de documentos con embeddings
- Implementar recuperaciÃ³n basada en similitud semÃ¡ntica
- Comparar respuestas con y sin RAG

## ğŸ“‹ Requisitos Previos

- Cuenta de AWS con acceso a Amazon Bedrock
- Python 3.8 o superior
- Credenciales de AWS configuradas
- Acceso habilitado a los modelos:
  - `amazon.titan-embed-text-v1` (para embeddings)
  - `anthropic.claude-3-haiku-20240307-v1:0` (para generaciÃ³n de texto)

## ğŸš€ ConfiguraciÃ³n del Entorno

### 1. Crear y activar entorno virtual

**En Windows:**
```bash
python -m venv rag-env
rag-env\Scripts\activate
```

**En Linux/Mac:**
```bash
python -m venv rag-env
source rag-env/bin/activate
```

### 2. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 3. Configurar credenciales de AWS

Si aÃºn no has configurado tus credenciales de AWS:

```bash
aws configure
```

Ingresa:
- AWS Access Key ID
- AWS Secret Access Key
- Default region name: `us-east-1`
- Default output format: `json`

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Usuario   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Query
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Sistema RAG                 â”‚
â”‚                                     â”‚
â”‚  1. Embedding de Query              â”‚
â”‚     (Titan Embed)                   â”‚
â”‚          â”‚                          â”‚
â”‚          â–¼                          â”‚
â”‚  2. BÃºsqueda en ChromaDB            â”‚
â”‚     (Similitud SemÃ¡ntica)           â”‚
â”‚          â”‚                          â”‚
â”‚          â–¼                          â”‚
â”‚  3. RecuperaciÃ³n de Documentos      â”‚
â”‚          â”‚                          â”‚
â”‚          â–¼                          â”‚
â”‚  4. ConstrucciÃ³n de Prompt          â”‚
â”‚     (Query + Contexto)              â”‚
â”‚          â”‚                          â”‚
â”‚          â–¼                          â”‚
â”‚  5. GeneraciÃ³n de Respuesta         â”‚
â”‚     (Claude 3 Haiku)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Estructura del Proyecto

```
aws-schoolars-ai-engineer-demos/
â”‚
â”œâ”€â”€ rag_system.py          # Sistema RAG completo
â”œâ”€â”€ requirements.txt       # Dependencias del proyecto
â”œâ”€â”€ README_RAG.md         # Este archivo
â”œâ”€â”€ main.py               # Demo de conversaciÃ³n con Bedrock
â””â”€â”€ example.py            # Ejemplo de Knowledge Base
```

## ğŸ”§ Componentes del Sistema

### 1. **Modelo de Embeddings**
- **Modelo:** `amazon.titan-embed-text-v1`
- **FunciÃ³n:** Convierte texto en vectores de alta dimensiÃ³n
- **Uso:** IndexaciÃ³n de documentos y bÃºsqueda semÃ¡ntica

### 2. **Base de Datos Vectorial**
- **TecnologÃ­a:** ChromaDB
- **FunciÃ³n:** Almacena y busca embeddings eficientemente
- **CaracterÃ­sticas:** BÃºsqueda por similitud de coseno

### 3. **Modelo de GeneraciÃ³n**
- **Modelo:** `anthropic.claude-3-haiku-20240307-v1:0`
- **FunciÃ³n:** Genera respuestas contextualizadas
- **Ventajas:** RÃ¡pido, preciso y cost-effective

## ğŸ’» Uso del Sistema

### Ejecutar el sistema completo

```bash
python rag_system.py
```

Este script:
1. âœ… Inicializa la conexiÃ³n con Amazon Bedrock
2. âœ… Crea una colecciÃ³n en ChromaDB
3. âœ… Indexa documentos de ejemplo
4. âœ… Realiza consultas de prueba
5. âœ… Compara respuestas con y sin RAG

### Funciones Principales

#### `get_bedrock_embedding(text)`
Obtiene el embedding de un texto usando Amazon Titan.

```python
embedding = get_bedrock_embedding("Amazon Bedrock es increÃ­ble")
```

#### `generate_text(prompt)`
Genera texto usando Claude 3 Haiku.

```python
response = generate_text("Â¿QuÃ© es RAG?")
```

#### `add_documents(docs)`
Agrega documentos a la base de datos vectorial.

```python
docs = ["Documento 1", "Documento 2"]
add_documents(docs)
```

#### `rag_generate(query, top_k=2)`
Genera respuesta usando RAG (con contexto).

```python
response = rag_generate("Â¿QuÃ© es Amazon Bedrock?", top_k=2)
```

#### `generate_without_rag(query)`
Genera respuesta sin RAG (sin contexto adicional).

```python
response = generate_without_rag("Â¿QuÃ© es Amazon Bedrock?")
```

## ğŸ§ª Ejemplo de Uso Personalizado

```python
import boto3
from rag_system import rag_generate, add_documents

# Agregar tus propios documentos
mis_documentos = [
    "Tu documento personalizado 1",
    "Tu documento personalizado 2",
    "Tu documento personalizado 3"
]
add_documents(mis_documentos)

# Hacer consultas
query = "Â¿QuÃ© informaciÃ³n tienes sobre...?"
respuesta = rag_generate(query, top_k=3)
print(respuesta)
```

## ğŸ“Š ComparaciÃ³n: RAG vs Sin RAG

El sistema automÃ¡ticamente compara respuestas:

| Aspecto | Con RAG | Sin RAG |
|---------|---------|---------|
| **PrecisiÃ³n** | Alta (usa contexto especÃ­fico) | Variable |
| **Relevancia** | Alta (documentos relevantes) | Depende del conocimiento del modelo |
| **ActualizaciÃ³n** | FÃ¡cil (agregar documentos) | Requiere reentrenamiento |
| **Costo** | Moderado | Bajo |

## ğŸ” Casos de Uso

1. **Chatbots empresariales** - Respuestas basadas en documentaciÃ³n interna
2. **Asistentes de soporte** - BÃºsqueda en base de conocimiento
3. **AnÃ¡lisis de documentos** - ExtracciÃ³n de informaciÃ³n relevante
4. **Q&A sobre productos** - Respuestas precisas sobre catÃ¡logos
5. **Asistentes educativos** - Respuestas basadas en material de curso

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Cambiar el modelo de generaciÃ³n

Edita `TEXT_GENERATION_MODEL` en `rag_system.py`:

```python
# Opciones disponibles:
TEXT_GENERATION_MODEL = "anthropic.claude-3-haiku-20240307-v1:0"  # RÃ¡pido y econÃ³mico
TEXT_GENERATION_MODEL = "anthropic.claude-3-sonnet-20240229-v1:0"  # Balance
TEXT_GENERATION_MODEL = "anthropic.claude-v2:1"  # Claude v2
```

### Ajustar parÃ¡metros de generaciÃ³n

```python
body = json.dumps({
    "anthropic_version": "bedrock-2023-05-31",
    "max_tokens": 1000,        # Aumentar para respuestas mÃ¡s largas
    "temperature": 0.5,        # 0.0-1.0 (menor = mÃ¡s determinista)
    "top_p": 0.9,             # 0.0-1.0 (control de diversidad)
    "messages": [...]
})
```

### Cambiar nÃºmero de documentos recuperados

```python
# Recuperar mÃ¡s documentos para mayor contexto
response = rag_generate(query, top_k=5)
```

## ğŸ› SoluciÃ³n de Problemas

### Error: "Could not connect to Bedrock"
- Verifica tus credenciales de AWS
- Confirma que tienes acceso a Amazon Bedrock
- Verifica la regiÃ³n (debe ser `us-east-1` o regiÃ³n con Bedrock habilitado)

### Error: "Model access denied"
- Ve a la consola de AWS Bedrock
- Solicita acceso a los modelos necesarios
- Espera la aprobaciÃ³n (puede tomar unos minutos)

### Error: "ChromaDB collection already exists"
- El script automÃ¡ticamente elimina colecciones existentes
- Si persiste, reinicia el script

## ğŸ“š Recursos Adicionales

- [DocumentaciÃ³n de Amazon Bedrock](https://docs.aws.amazon.com/bedrock/)
- [ChromaDB Documentation](https://docs.trychroma.com/)
- [Anthropic Claude Documentation](https://docs.anthropic.com/)
- [Repositorio del curso](https://github.com/udacity/cd13926-Building-Apps-Amazon-Bedrock-exercises)

## ğŸ“ Aprendizajes Clave

1. **RAG mejora significativamente la precisiÃ³n** de las respuestas al proporcionar contexto relevante
2. **Los embeddings permiten bÃºsqueda semÃ¡ntica** mÃ¡s allÃ¡ de coincidencias de palabras clave
3. **ChromaDB facilita la gestiÃ³n** de bases de datos vectoriales
4. **Amazon Bedrock simplifica** el acceso a modelos de IA de Ãºltima generaciÃ³n
5. **La combinaciÃ³n de recuperaciÃ³n y generaciÃ³n** crea sistemas mÃ¡s robustos

## ğŸ“ Notas

- Los embeddings se generan automÃ¡ticamente al agregar documentos
- La bÃºsqueda usa similitud de coseno por defecto
- El sistema es stateless (no mantiene historial de conversaciÃ³n)
- Para producciÃ³n, considera usar bases de datos vectoriales persistentes

## ğŸš€ PrÃ³ximos Pasos

1. Agregar mÃ¡s documentos especÃ­ficos de tu dominio
2. Implementar persistencia de la base de datos vectorial
3. Agregar manejo de historial de conversaciÃ³n
4. Implementar mÃ©tricas de evaluaciÃ³n
5. Crear una interfaz web con Streamlit o Gradio

---

**Â¡Feliz aprendizaje con RAG y Amazon Bedrock!** ğŸ‰
